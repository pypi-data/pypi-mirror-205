{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c7a3f1-ab43-432e-a64f-b7f1358a24da",
   "metadata": {},
   "source": [
    "# Storing training data on disk via Zarr\n",
    "\n",
    "First we need some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9d04e5-d08e-46ab-a520-4547dedf0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0297c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pylab as plt\n",
    "import torch\n",
    "import torchist\n",
    "import swyft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab99366b-0783-46f5-be2d-80cbbb85e163",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training data\n",
    "\n",
    "Now we generate training data.  As simple example, we consider the model\n",
    "\n",
    "$$\n",
    "x = z + \\epsilon\n",
    "$$\n",
    "\n",
    "where the parameter $z \\sim \\mathcal{N}(\\mu = 0, \\sigma = 1)$ is standard normal distributed, and $\\epsilon \\sim \\mathcal{N}(\\mu = 0, \\sigma = 0.1)$ is a small noise contribution.  We are interested in the posterior of $z$ given a measurement of parameter $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0439f14-d49f-4e52-8916-49a785daede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(swyft.Simulator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.transform_samples = swyft.to_numpy32\n",
    "\n",
    "    def build(self, graph):\n",
    "        z = graph.node('z', lambda: np.random.rand(1))\n",
    "        x = graph.node('x', lambda z: z + np.random.randn(1)*0.1, z)\n",
    "        \n",
    "sim = Simulator()\n",
    "shapes, dtypes = sim.get_shapes_and_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "315a3a80-c59b-4daf-b846-afb452b7575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Already initialized.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<swyft.lightning.stores.ZarrStore at 0x1463d9eeb0d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = swyft.ZarrStore(\"./zarr_store666\")\n",
    "store.init(10000, 64, shapes, dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1ed06f-9bbe-460d-bda3-400a3eaee6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.simulate(sim, batch_size = 1000)  # This function can be run in parallel in many threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e6dc7e9-ff0a-479d-a4e8-fd8025717327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(swyft.SwyftModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.logratios = swyft.LogRatioEstimator_1dim(num_features = 1, num_params = 1, varnames = 'z')\n",
    "\n",
    "    def forward(self, A, B):\n",
    "        logratios = self.logratios(A['x'], B['z'])\n",
    "        return logratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2554dbed-fc91-45d2-bfa7-418cdaad67b6",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "\n",
    "Training is now done using the `SwyftTrainer` class, which extends `pytorch_lightning.Trainer` by methods like `infer` (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5683ce37-a8d0-4ed7-94a6-512ccc7babcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = swyft.SwyftTrainer(accelerator = 'gpu', devices=1, max_epochs = 2, precision = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053eff99-5d2b-4419-bce7-d938831b623e",
   "metadata": {},
   "source": [
    "The `swyft.Samples` class provides convenience functions to generate data loaders for training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80bdb59a-4d64-4508-8709-68c789a8a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = swyft.SwyftDataModule(store, fractions = [0.8, 0.1, 0.1], batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5811d37-d10b-49e8-a8ed-1e6d43caefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41f7765b-45b8-4684-b820-4f75c9719857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/weniger/codes/swyft/notebooks/lightning_logs/version_10036357/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | logratios | LogRatioEstimator_1dim | 17.4 K\n",
      "-----------------------------------------------------\n",
      "17.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.4 K    Total params\n",
      "0.139     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weniger/miniconda3b/envs/zero/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 32it [00:00, 77.04it/s, loss=-0.494, v_num=1e+7] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: : 33it [00:00, 76.08it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 34it [00:00, 76.88it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 35it [00:00, 78.22it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 36it [00:00, 78.91it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 37it [00:00, 80.10it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 38it [00:00, 80.78it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 39it [00:00, 81.95it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 40it [00:00, 82.44it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 41it [00:00, 83.48it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 42it [00:00, 83.99it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 43it [00:00, 85.01it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 44it [00:00, 85.45it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 45it [00:00, 86.35it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 46it [00:00, 86.65it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 47it [00:00, 87.62it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 48it [00:00, 87.94it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 49it [00:00, 88.75it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 50it [00:00, 89.15it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 51it [00:00, 90.04it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 52it [00:00, 90.32it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 53it [00:00, 91.09it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 54it [00:00, 91.37it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 55it [00:00, 92.18it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 56it [00:00, 92.39it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 57it [00:00, 93.09it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 58it [00:00, 93.48it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 59it [00:00, 94.42it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 60it [00:00, 94.80it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 61it [00:00, 95.65it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 62it [00:00, 95.98it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 63it [00:00, 96.68it/s, loss=-0.494, v_num=1e+7]\n",
      "Epoch 0: : 64it [00:00, 93.70it/s, loss=-0.494, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 32it [00:00, 81.83it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: : 33it [00:00, 80.67it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 34it [00:00, 81.37it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 35it [00:00, 82.76it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 36it [00:00, 83.44it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 37it [00:00, 84.70it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 38it [00:00, 85.33it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 39it [00:00, 86.63it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 40it [00:00, 87.20it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 41it [00:00, 88.32it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 42it [00:00, 88.72it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 43it [00:00, 89.80it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 44it [00:00, 90.29it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 45it [00:00, 91.36it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 46it [00:00, 91.79it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 47it [00:00, 92.71it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 48it [00:00, 93.13it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 49it [00:00, 94.22it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 50it [00:00, 94.60it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 51it [00:00, 95.57it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 52it [00:00, 95.85it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 53it [00:00, 96.69it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 54it [00:00, 96.69it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 55it [00:00, 97.58it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 56it [00:00, 97.79it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 57it [00:00, 98.46it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 58it [00:00, 98.73it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 59it [00:00, 99.55it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 60it [00:00, 99.52it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 61it [00:00, 100.37it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 62it [00:00, 100.74it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 63it [00:00, 101.59it/s, loss=-0.544, v_num=1e+7, val_loss=-.105]\n",
      "Epoch 1: : 64it [00:00, 102.25it/s, loss=-0.544, v_num=1e+7, val_loss=-.496]\n",
      "Epoch 1: : 64it [00:00, 101.83it/s, loss=-0.544, v_num=1e+7, val_loss=-.496]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 64it [00:00, 99.26it/s, loss=-0.544, v_num=1e+7, val_loss=-.496] \n"
     ]
    }
   ],
   "source": [
    "trainer.fit(network, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863fb41-2d1a-49db-a8f6-29ce8325356f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
