Metadata-Version: 2.1
Name: starlette-cache
Version: 0.1.2
Summary: Cache for Starlette
Home-page: https://github.com/lesleslie/starlette-cache
Author-Email: lesleslie <les@wedgwoodwebworks.com>
License: BSD-3-Clause
Project-URL: Homepage, https://github.com/lesleslie/starlette-cache
Project-URL: Documentation, https://github.com/lesleslie/starlette-cache
Project-URL: Repository, https://github.com/lesleslie/starlette-cache
Requires-Python: >=3.11
Requires-Dist: starlette>=0.26.1
Requires-Dist: uvicorn>=0.21.1
Requires-Dist: redis>=4.5.4
Requires-Dist: aiomcache>=0.8.1
Requires-Dist: pendulum>=2.1.2
Requires-Dist: aiohttp>=3.8.4
Requires-Dist: typing-extensions>=4.5.0
Requires-Dist: msgspec>=0.14.1
Requires-Dist: acb>=0.1.4
Requires-Dist: starlette-async-jinja>=0.1.1
Description-Content-Type: text/markdown

# starlette-cache

Starlette fork of Starlette Cache with the fastapi_cache dependency removed.


## Introduction

`fastapi-cache` is a tool to cache fastapi response and function result, with backends support `redis`, `memcache`,
and `dynamodb`.

## Features

- Support `redis`, `memcache`, `dynamodb`, and `in-memory` backends.
- Easily integration with `fastapi`.
- Support http cache like `ETag` and `Cache-Control`.

## Requirements

- `asyncio` environment.
- `redis` if use `RedisBackend`.
- `memcache` if use `MemcacheBackend`.
- `aiobotocore` if use `DynamoBackend`.

## Install

```shell
> pdm add startlette-cache
```

## Usage

### Quick Start

```python
from starlette import Starlette
from starlette.requests import Request
from starlette.responses import Response

from starlette_cache import StarletteCache
from starlette_cache.backends.redis import RedisBackend
from starlette_cache.decorator import cache

from redis import asyncio as aioredis

app = Starlette()


@cache()
async def get_cache():
    return 1


@app.get("/")
@cache(expire=60)
async def index():
    return dict(hello="world")


@app.on_event("startup")
async def startup():
    redis = aioredis.from_url("redis://localhost", encoding="utf8", decode_responses=True)
    StarletteCache.init(RedisBackend(redis), prefix="fastapi-cache")

```

### Initialization

Firstly you must call `StarletteCache.init` on startup event of `fastapi`, there are some global config you can pass in.

### Use `cache` decorator

If you want cache `fastapi` response transparently, you can use `cache` as decorator between router decorator and view
function and must pass `request` as param of view function.

Parameter | type, description
------------ | -------------
expire | int, states a caching time in seconds
namespace | str, namespace to use to store certain cache items
coder | which coder to use, e.g. JsonCoder
key_builder | which key builder to use, default to builtin

You can also use `cache` as decorator like other cache tools to cache common function result.

### Custom coder

By default use `JsonCoder`, you can write custom coder to encode and decode cache result, just need
inherit `fastapi_cache.coder.Coder`.

```python
@app.get("/")
@cache(expire=60, coder=JsonCoder)
async def index():
    return dict(hello="world")
```

### Custom key builder

By default, use builtin key builder. If you need, you can override this and pass in `cache` or `StarletteCache.init` to
take effect globally.

```python
def my_key_builder(
        func,
        namespace: Optional[str] = "",
        request: Request = None,
        response: Response = None,
        *args,
        **kwargs,
):
    prefix = StarletteCache.get_prefix()
    cache_key = f"{prefix}:{namespace}:{func.__module__}:{func.__name__}:{args}:{kwargs}"
    return cache_key


@app.get("/")
@cache(expire=60, coder=JsonCoder, key_builder=my_key_builder)
async def index():
    return dict(hello="world")
```

### InMemoryBackend

`InMemoryBackend` store cache data in memory and use lazy delete, which mean if you don't access it after cached, it
will not delete automatically.

## Tests and coverage

## Acknowlegdments
