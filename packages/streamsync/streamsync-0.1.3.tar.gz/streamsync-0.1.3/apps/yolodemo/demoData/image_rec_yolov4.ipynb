{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Package requirements for thsi include: Pillow opencv-python keras tensorflow pandas numpy\n",
    "2. Need to download yolov3.cfg from [here](https://github.com/qqwweee/keras-yolo3/blob/master/yolov3.cfg), and yolov3.weights from [here](https://pjreddie.com/darknet/yolo/)\n",
    "3. Convert the weights to a keras model with the `convert.py` script downloaded from [here](https://github.com/qqwweee/keras-yolo3/blob/master/convert.py), and by running the following command:\n",
    "```bash\n",
    "python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5\n",
    "```\n",
    "4. Retrieve yolo class labels from [this repository](https://github.com/leggedrobotics/darknet_ros/blob/master/darknet_ros/config/yolov3.yaml), and save it as json config\n",
    "\n",
    "Note: some imports of the `convert.py` script are broken, corrected version included in current repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "- Add the class label to the image\n",
    "- Add other of the 80 class levels (not only driving related)\n",
    "- Modify the drawing function to make it more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('server/demoData/classes.json', 'r') as handle:\n",
    "    class_dict = json.load(handle)\n",
    "    class_dict = {int(key):val for key,val in class_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the YOLO model to detect objects.\n",
    "def load_network(config_path=\"yolov3.cfg\", weights_path=\"yolov3.weights\"):\n",
    "        net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "        output_layer_names = net.getLayerNames()\n",
    "        output_layer_names = [output_layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        return net, output_layer_names\n",
    "\n",
    "def yolo_v3(image, net, output_layer_names, confidence_threshold=0.8, overlap_threshold=0.6, class_dict=class_dict):\n",
    "    # Run the YOLO neural net.\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layer_outputs = net.forward(output_layer_names)\n",
    "    print(layer_outputs)\n",
    "    # Supress detections in case of too low confidence or too much overlap.\n",
    "    boxes, confidences, class_IDs = [], [], []\n",
    "    H, W = image.shape[:2]\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > confidence_threshold:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                centerX, centerY, width, height = box.astype(\"int\")\n",
    "                x, y = int(centerX - (width / 2)), int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_IDs.append(classID)\n",
    "    print(boxes)\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, overlap_threshold)\n",
    "    if len(indices) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in indices.flatten():\n",
    "            label = class_dict.get(class_IDs[i], None)\n",
    "            if label is None:\n",
    "                continue\n",
    "            # extract the bounding box coordinates\n",
    "            x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
    "            cv2.rectangle(image, (x,y), (x+w,y+h),(0,255,0),2)\n",
    "            label_conf = \"{0:.0%}\".format(confidences[i])\n",
    "            text_label = f\"{label}: {label_conf}\"\n",
    "            (text_w, text_h), _ = cv2.getTextSize(\n",
    "                text_label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1\n",
    "            )\n",
    "            # Prints the text.    \n",
    "            image = cv2.rectangle(image, (x, y - 20), (x + text_w, y), (0,255,0), -1)\n",
    "            image = cv2.putText(image, text_label, (x, y - 5),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "            return image\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, output_layer_name = load_network(config_path=\"server/demoData/yolov4-tiny.cfg\", weights_path=\"server/demoData/yolov4-tiny.weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import urllib\n",
    "import io\n",
    "from PIL import Image\n",
    "with open(\"server/demoData/payload.pkl\", \"rb\") as handle:\n",
    "    url = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.06135021, 0.0514141 , 0.16222665, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.05640702, 0.0358826 , 0.2058261 , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.04281428, 0.02809551, 0.6480995 , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.9365355 , 0.9499279 , 0.20856318, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9382085 , 0.9396104 , 0.26385367, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9576482 , 0.9354702 , 0.57431793, ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32), array([[0.02665966, 0.01862338, 0.0605887 , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.0264577 , 0.03181205, 0.07697888, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.01927491, 0.02908181, 0.25845245, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.97184473, 0.9744586 , 0.05659508, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9751301 , 0.96658295, 0.08104827, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9828285 , 0.971161  , 0.2708039 , ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32))\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "with urllib.request.urlopen(url) as file:\n",
    "    content = file.read()\n",
    "nparr = np.frombuffer(content, np.uint8)\n",
    "img = cv2.imdecode(nparr, flags=cv2.IMREAD_COLOR)\n",
    "image = yolo_v3(img, net, output_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Net 0000022FF531ED10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:976: error: (-215:Assertion failed) !image.empty() in function 'cv::imencode'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e759bbe52456>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:976: error: (-215:Assertion failed) !image.empty() in function 'cv::imencode'\n"
     ]
    }
   ],
   "source": [
    "img_str = cv2.imencode('.png', image)[1].tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:976: error: (-215:Assertion failed) !image.empty() in function 'cv::imencode'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4cf83b7cfab6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:976: error: (-215:Assertion failed) !image.empty() in function 'cv::imencode'\n"
     ]
    }
   ],
   "source": [
    "cv2.imencode('.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base64.encodebytes(img_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.dumpToFile(\"model.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = cv2.dnn.readNet(\"model.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3395594879b561353b46b7c9378610339c1c3c34adb3749f33a7027073cbcfc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
