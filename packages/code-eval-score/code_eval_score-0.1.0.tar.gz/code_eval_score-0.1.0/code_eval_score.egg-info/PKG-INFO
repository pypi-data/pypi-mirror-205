Metadata-Version: 2.1
Name: code-eval-score
Version: 0.1.0
Summary: Automated evaluation of generated code based on CodeBERT and CodeT5.
Home-page: https://github.com/Lizhmq/code-eval-score
Author: Zhuo Li
Author-email: lizhmq@pku.edu.cn
License: MIT
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Python :: Implementation :: PyPy
Requires-Python: >=3.6.0
Description-Content-Type: text/markdown
License-File: LICENSE


# Code-eval-score
This is a package for evaluting the quality of code generated by AI models.

We provide two ways to evaluate the code quality:
* MatchScore: uses the CodeBERT model to calculate the similarity between the hypothesis code and the reference code.
* GenScore: uses the CodeT5 model to calculate the probability of generating hypothesis code from the reference code.

Paper comming soon.
[Contact to the author](https://github.com/Lizhmq)
